{
  "hash": "81a47c7316dd1a58f745a4d671e3dcd6",
  "result": {
    "markdown": "---\noutput: html_document\nexecute: \n  freeze: auto\neditor_options: \n  chunk_output_type: console\n---\n\n\n# Harmonizing SumStats II\n\nPreviously, we demonstrated the harmonization of a single exposure-outcome pair. Here, we expand on this concept by harmonizing multiple exposure-outcome trait pairs using the `map` functions from the `purrr` package. However, it is important to note that due to the size of some summary statistic files, memory limits may become an issue when running these scripts locally. As the number of exposure-outcome pairs increases, it becomes even more important to invest in functional programming and develop reproducible, adaptable, and transparent [computational workflows]((https://raps-with-r.dev/)) that can handle large-scale data analysis ([Targets](https://books.ropensci.org/targets/) in R; [Snakemake](https://snakemake.readthedocs.io/en/stable/) in Python). By doing so, we can increase efficiency, reduce errors, and make our research more accessible and reproducible to others.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Load R Packages\"}\nlibrary(tidyverse)    # Data wrangling \nlibrary(TwoSampleMR)  # MR \nlibrary(LDlinkR)      # LD and proxy snps\n\n# Usr defined functions \nsource('scripts/munge_proxies.R')\nsource('scripts/misc_functions.R')\n```\n:::\n\n\n## Exposure dataset\n\nOur exposures of interest LDL cholesteral level, with GWAS summary statistics obtained from two separate GWAS conducted by the Global Lipid Genetics Consortium. The first GWAS, conducted by Willer et al. in 2013, included 188,577 individuals and identified 56 loci that were significantly associated with LDL cholesterol levels. The second GWAS, conducted by Graham et al. in 2021, included a much larger sample size of approximately 1.65 million individuals, which included 350,000 individuals of non-European ancestry. In the subset of individuals of European ancestry (n = 1,320,016), 403 loci were identified as being significantly associated with LDL cholesterol levels.\n\nThe process of importing and clumping the exposure datasets remains the same as before, except that now we are excluding rare variants with a minor allele frequency (MAF) of less than 0.01. This is done to reduce the file size.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Import exposure GWAS SumStats\"}\nexposure_paths = c(\n  \"resources/Graham2021ldl.chrall.CPRA_b37.tsv.gz\",\n  \"resources/Willer2013ldl.chrall.CPRA_b37.tsv.gz\" \n)\nexposures <- str_extract(exposure_paths, \"(?<=/).*(?=.chrall)\")\n\nexposure_ss <- map(exposure_paths, function(x){\n  trait <- str_extract(x, \"(?<=/).*(?=.chrall)\")\n  \n  message(\"Imporing: \", x, \"....\")\n  ## Filter out problematic snps - MAF > 1%, SNVs, rsid\n  ss <- read_tsv(\n    x, comment = \"##\", col_types = coltypes,\n    col_select = c(DBSNP_ID, CHROM, POS, REF, ALT, AF, BETA, SE, Z, P, N, TRAIT))  %>%\n    filter(between(AF, 0.01, 0.99)) %>%\n    filter(nchar(REF) == 1 & nchar(ALT) == 1) %>%\n    filter(!is.na(DBSNP_ID)) %>%\n    mutate(TRAIT = trait)\n    \n  message(\"Standardizing: \", x, \"....\")\n   ss_out <- ss %>% format_data(.,\n      type = \"exposure\",\n      snps = NULL,\n      header = TRUE,\n      phenotype_col = \"TRAIT\",\n      snp_col = \"DBSNP_ID\",\n      beta_col = \"BETA\",\n      se_col = \"SE\",\n      eaf_col = \"AF\",\n      effect_allele_col = \"ALT\",\n      other_allele_col = \"REF\",\n      pval_col = \"P\",\n      samplesize_col = \"N\",\n      z_col = \"Z\",\n      chr_col = \"CHROM\",\n      pos_col = \"POS\",\n      log_pval = FALSE\n    ) %>%\n    as_tibble()\n  \n   rm(ss) \n    ss_out\n  }) %>%\n  magrittr::set_names(exposures)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"LD clump exposure\"}\n# Perform LD clumping on SNP data, filter SNPs to make it run faster\nexposure_clump <- map(exposure_ss, function(x){\n    x %>% \n      filter(pval.exposure < 1e-8) %>%\n      clump_data(.,\n      clump_kb = 10000,\n      clump_r2 = 0.001,\n      clump_p1 = 1,\n      clump_p2 = 1,\n      pop = \"EUR\"\n  )\n}) \n\nexposure_dat <- bind_rows(exposure_clump)\n```\n:::\n\n\n## Outcome datasets\n\nOur outcomes consist of GWAS of clinical late onset Alzheimer's disease by Kunkle et al 2019 and AD/dementia by Bellenguez et al 2022. Importing, identifying proxy variants, and harmonizing the datasets remains the same as before. \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Import outcome GWAS SumStats\"}\noutcome_paths = c(\n  \"resources/Kunkle2019load_stage123.chrall.CPRA_b37.tsv.gz\", \n  \"resources/Bellenguez2022load.chrall.CPRA_b37.tsv.gz\"\n  )\n\noutcomes <- str_extract(outcome_paths, \"(?<=/).*(?=.chrall)\")\n\noutcome_ss <- map(outcome_paths, function(x){\n  trait <- str_extract(x, \"(?<=/).*(?=.chrall)\")\n  \n  message(\"Imporing: \", x, \"....\")\n  ## Filter out problematic snps - MAF > 1%, SNVs, rsid\n  ss <- read_tsv(\n    x, comment = \"##\", col_types = coltypes, # n_max = 100,\n    col_select = c(DBSNP_ID, CHROM, POS, REF, ALT, AF, BETA, SE, Z, P, N, TRAIT))  %>%\n    filter(between(AF, 0.01, 0.99)) %>%\n    filter(nchar(REF) == 1 & nchar(ALT) == 1) %>%\n    filter(!is.na(DBSNP_ID)) %>%\n    mutate(TRAIT = trait)\n    \n  message(\"Standardizing: \", x, \"....\")\n   ss_out <- ss %>% format_data(.,\n      type = \"outcome\",\n      snps = NULL,\n      header = TRUE,\n      phenotype_col = \"TRAIT\",\n      snp_col = \"DBSNP_ID\",\n      beta_col = \"BETA\",\n      se_col = \"SE\",\n      eaf_col = \"AF\",\n      effect_allele_col = \"ALT\",\n      other_allele_col = \"REF\",\n      pval_col = \"P\",\n      samplesize_col = \"N\",\n      z_col = \"Z\",\n      chr_col = \"CHROM\",\n      pos_col = \"POS\",\n      log_pval = FALSE\n    ) %>%\n    as_tibble()\n  \n   rm(ss) \n    ss_out\n  }) %>%\n  magrittr::set_names(outcomes)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Identify Proxy Variants\"}\n# extract exposure SNPs present in outcome\noutcome_clump <- map(outcome_ss, function(x){\n    semi_join(\n      x, exposure_dat, by = \"SNP\"\n    )\n})\n\n# Exposure SNPs not present in outomce\nexp_snps_wo <- map(outcome_ss, function(x){\n  anti_join(\n    exposure_dat, x, by = \"SNP\"\n  )\n})\n\n# Use LDLinkR to identify proxy snps\nmap2(exp_snps_wo, outcomes, function(x,y){\n  LDproxy_batch(x$SNP, \n        pop = \"CEU\",             # Match population ancestries\n        r2d = \"r2\", \n        token = 'a6deee62cc4a', \n        append = TRUE,           # We appended the results of each LDlink query to a single file\n        genome_build = \"grch37\") # Select genome build based on summary stats\n  \n  system(glue(\"mv combined_query_snp_list_grch37.txt data/exposure_{y}_proxy_snps.txt\"))\n  })\n\n# Munge proxy snp file\noutcome_dat <- pmap(list(outcomes, outcome_ss, outcome_clump), \n                    function(file, sumstats, clumped){\n                      munge_proxies(glue(\"data/exposure_{file}_proxy_snps.txt\"), \n                                    sumstats, clumped)\n}) %>%\n  bind_rows()\n```\n:::\n\n\nDuring the harmonization step we are now flagging SNPs that are GWS for the outcome or that are located in the *APOE* region for removal.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Harmonize\"}\nmr_dat <- harmonise_data(exposure_dat, test, action = 2) %>% \n  as_tibble() %>%\n   mutate(\n     apoe_region = case_when(\n       chr.outcome == 19 & between(pos.outcome, 44912079, 45912079) ~ TRUE,\n       TRUE ~ FALSE\n     ),\n     gws.outcome = ifelse(pval.outcome < 5e-8, TRUE, FALSE),\n    mr_keep = ifelse(mr_keep == FALSE | apoe_region == TRUE | gws.outcome == TRUE, FALSE, TRUE)\n   )\n```\n:::\n\n::: {.cell}\n\n:::\n",
    "supporting": [
      "mr_harmonization_II_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}